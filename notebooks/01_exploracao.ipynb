{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b77a609",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ Setup do ambiente e criaÃ§Ã£o da SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a335fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"EDA - Rossmann\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa772c45",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614db2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_path = \"../data/raw/rossmann_store_sales/train.csv\"\n",
    "store_path = \"../data/raw/rossmann_store_sales/store.csv\"\n",
    "\n",
    "df_train = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(train_path)\n",
    "df_store = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded94de6",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ AnÃ¡lise inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f2c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Sales: integer (nullable = true)\n",
      " |-- Customers: integer (nullable = true)\n",
      " |-- Open: integer (nullable = true)\n",
      " |-- Promo: integer (nullable = true)\n",
      " |-- StateHoliday: string (nullable = true)\n",
      " |-- SchoolHoliday: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- StoreType: string (nullable = true)\n",
      " |-- Assortment: string (nullable = true)\n",
      " |-- CompetitionDistance: integer (nullable = true)\n",
      " |-- CompetitionOpenSinceMonth: integer (nullable = true)\n",
      " |-- CompetitionOpenSinceYear: integer (nullable = true)\n",
      " |-- Promo2: integer (nullable = true)\n",
      " |-- Promo2SinceWeek: integer (nullable = true)\n",
      " |-- Promo2SinceYear: integer (nullable = true)\n",
      " |-- PromoInterval: string (nullable = true)\n",
      "\n",
      "+-----+---------+----------+-----+---------+----+-----+------------+-------------+\n",
      "|Store|DayOfWeek|      Date|Sales|Customers|Open|Promo|StateHoliday|SchoolHoliday|\n",
      "+-----+---------+----------+-----+---------+----+-----+------------+-------------+\n",
      "|    1|        5|2015-07-31| 5263|      555|   1|    1|           0|            1|\n",
      "|    2|        5|2015-07-31| 6064|      625|   1|    1|           0|            1|\n",
      "|    3|        5|2015-07-31| 8314|      821|   1|    1|           0|            1|\n",
      "|    4|        5|2015-07-31|13995|     1498|   1|    1|           0|            1|\n",
      "|    5|        5|2015-07-31| 4822|      559|   1|    1|           0|            1|\n",
      "+-----+---------+----------+-----+---------+----+-----+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+---------+----------+-------------------+-------------------------+------------------------+------+---------------+---------------+---------------+\n",
      "|Store|StoreType|Assortment|CompetitionDistance|CompetitionOpenSinceMonth|CompetitionOpenSinceYear|Promo2|Promo2SinceWeek|Promo2SinceYear|  PromoInterval|\n",
      "+-----+---------+----------+-------------------+-------------------------+------------------------+------+---------------+---------------+---------------+\n",
      "|    1|        c|         a|               1270|                        9|                    2008|     0|           NULL|           NULL|           NULL|\n",
      "|    2|        a|         a|                570|                       11|                    2007|     1|             13|           2010|Jan,Apr,Jul,Oct|\n",
      "|    3|        a|         a|              14130|                       12|                    2006|     1|             14|           2011|Jan,Apr,Jul,Oct|\n",
      "|    4|        c|         c|                620|                        9|                    2009|     0|           NULL|           NULL|           NULL|\n",
      "|    5|        a|         a|              29910|                        4|                    2015|     0|           NULL|           NULL|           NULL|\n",
      "+-----+---------+----------+-------------------+-------------------------+------------------------+------+---------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Train rows: 1017209 | Store rows: 1115\n"
     ]
    }
   ],
   "source": [
    "# Visualizar schema\n",
    "df_train.printSchema()\n",
    "df_store.printSchema()\n",
    "\n",
    "# Visualizar algumas linhas\n",
    "df_train.show(5)\n",
    "df_store.show(5)\n",
    "\n",
    "# Visualizar quantidade de linhas em cada DataFrame\n",
    "print(f\"Train rows: {df_train.count()} | Store rows: {df_store.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b2343",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ Verificando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a6b6632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos/NaN de train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----+-----+---------+----+-----+------------+-------------+\n",
      "|Store|DayOfWeek|Date|Sales|Customers|Open|Promo|StateHoliday|SchoolHoliday|\n",
      "+-----+---------+----+-----+---------+----+-----+------------+-------------+\n",
      "|    0|        0|   0|    0|        0|   0|    0|           0|            0|\n",
      "+-----+---------+----+-----+---------+----+-----+------------+-------------+\n",
      "\n",
      "Valores nulos/NaN de store\n",
      "+-----+---------+----------+-------------------+-------------------------+------------------------+------+---------------+---------------+-------------+\n",
      "|Store|StoreType|Assortment|CompetitionDistance|CompetitionOpenSinceMonth|CompetitionOpenSinceYear|Promo2|Promo2SinceWeek|Promo2SinceYear|PromoInterval|\n",
      "+-----+---------+----------+-------------------+-------------------------+------------------------+------+---------------+---------------+-------------+\n",
      "|    0|        0|         0|                  3|                      354|                     354|     0|            544|            544|          544|\n",
      "+-----+---------+----------+-------------------+-------------------------+------------------------+------+---------------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when, lit\n",
    "from pyspark.sql.types import DoubleType, FloatType\n",
    "\n",
    "def missing_values(df):\n",
    "    return df.select([\n",
    "        count(when(col(c).isNull() | (isnan(col(c)) if df.dtypes in [\"double\", \"float\"] else lit(False)), c)).alias(c)\n",
    "        for c in df.columns\n",
    "    ])\n",
    "\n",
    "print(\"Valores nulos/NaN de train\")\n",
    "missing_values(df_train).show()\n",
    "\n",
    "print(\"Valores nulos/NaN de store\")\n",
    "missing_values(df_store).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16517c4",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ EstatÃ­sticas descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7479a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|             Sales|        Customers|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|           1017209|          1017209|\n",
      "|   mean| 5773.818972305593|633.1459464082602|\n",
      "| stddev|3849.9261752347525|464.4117338866323|\n",
      "|    min|                 0|                0|\n",
      "|    max|             41551|             7388|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.describe([\"Sales\", \"Customers\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6164f820",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ Algumas anÃ¡lises especÃ­ficas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd496fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|DayOfWeek|        avg(Sales)|\n",
      "+---------+------------------+\n",
      "|        1| 7809.044510467767|\n",
      "|        2| 7005.244466717926|\n",
      "|        3| 6555.884138262451|\n",
      "|        4|  6247.57591278412|\n",
      "|        5|  6723.27430491275|\n",
      "|        6| 5847.562599322877|\n",
      "|        7|204.18318938713466|\n",
      "+---------+------------------+\n",
      "\n",
      "+-----+-----------------+\n",
      "|Promo|       avg(Sales)|\n",
      "+-----+-----------------+\n",
      "|    1|7991.152045969903|\n",
      "|    0|4406.050805160786|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "# MÃ©dia de vendas por dia da semana\n",
    "df_train.groupBy(\"DayOfWeek\").avg(\"Sales\").orderBy(\"DayOfWeek\").show()\n",
    "\n",
    "# Impacto das vendas\n",
    "df_train.groupBy(\"Promo\").avg(\"Sales\").show()\n",
    "\n",
    "# Converter a data para timestamp (para o caso de usos futuros)\n",
    "df_train_no_timestamp = df_train\n",
    "df_train = df_train.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a603fb7",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ Merge com os dados de loja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f846cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Sales: integer (nullable = true)\n",
      " |-- Customers: integer (nullable = true)\n",
      " |-- Open: integer (nullable = true)\n",
      " |-- Promo: integer (nullable = true)\n",
      " |-- StateHoliday: string (nullable = true)\n",
      " |-- SchoolHoliday: integer (nullable = true)\n",
      " |-- StoreType: string (nullable = true)\n",
      " |-- Assortment: string (nullable = true)\n",
      " |-- CompetitionDistance: integer (nullable = true)\n",
      " |-- CompetitionOpenSinceMonth: integer (nullable = true)\n",
      " |-- CompetitionOpenSinceYear: integer (nullable = true)\n",
      " |-- Promo2: integer (nullable = true)\n",
      " |-- Promo2SinceWeek: integer (nullable = true)\n",
      " |-- Promo2SinceYear: integer (nullable = true)\n",
      " |-- PromoInterval: string (nullable = true)\n",
      "\n",
      "+---------+------------------+\n",
      "|StoreType|        avg(Sales)|\n",
      "+---------+------------------+\n",
      "|        d| 5641.819243109884|\n",
      "|        c|5723.6292458345515|\n",
      "|        b|10058.837334175616|\n",
      "+---------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_train.join(df_store, on=\"Store\", how=\"left\")\n",
    "df_merged.printSchema()\n",
    "df_merged.select(\"StoreType\", \"Sales\").groupBy(\"StoreType\").avg(\"Sales\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7de7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
